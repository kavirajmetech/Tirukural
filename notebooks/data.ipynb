{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(filename):\n",
    "    text=[]\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text= file.readlines()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these files are large, so, download from the given drive link place in local folder out of this git folder and give correct path\n",
    "valid_data=extract_text(r'main_train_valid.txt') # drive link https://drive.google.com/file/d/1nayau6YKexlTarp34i4SG1m3ko5nCjzi/view?usp=sharing\n",
    "train_data=extract_text(r'main_train_train.txt') # drive link https://drive.google.com/file/d/19_H_0AdIi1r2W-eoZbmVMdf54BGdStBy/view?usp=sharing\n",
    "parimelazhagar_vurai=extract_text(r'../datasets/parimelazhagar.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    alltokens = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_text = re.sub(r'[^ஃ-உஂ-ௐஂ-௿\\s]', '', sentence) \n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "        cleaned_text = cleaned_text.strip()  \n",
    "        tokens = cleaned_text.split()\n",
    "        alltokens.append(tokens)\n",
    "    return alltokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tirukural_tokens=set()\n",
    "def get_parimelazhagar_merged_tokens(list):\n",
    "    data=[]\n",
    "    pattern=re.compile(r'[ \\n$().,:;?! ]+')  \n",
    "    for item in list:\n",
    "        a=item.split(\"=\")\n",
    "        if(len(a)!=2):\n",
    "            continue\n",
    "        b = re.sub(r'[^ஃ-உஂ-ௐஂ-௿\\s]', '', a[0]) \n",
    "        b = re.sub(r'\\s+', ' ', b)\n",
    "        c = re.sub(r'[^ஃ-உஂ-ௐஂ-௿\\s]', '', a[1]) \n",
    "        c = re.sub(r'\\s+', ' ', c)\n",
    "        b,c=b.split(),c.split()\n",
    "        for i in b:\n",
    "            tirukural_tokens.add(i)  \n",
    "        for _ in range(20):\n",
    "            merged = []\n",
    "            i, j = 0, 0\n",
    "            while i < len(b) and j< len(c):\n",
    "                if random.choice([False,False,True,False,False,True,False,False,True,True,True]):\n",
    "                    merged.append(b[i])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    merged.append(c[j])\n",
    "                    j+=1\n",
    "            \n",
    "            merged.extend(b[i:])\n",
    "            merged.extend(c[j:])\n",
    "                \n",
    "            data.append(merged)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kural_mk_mv_sp():\n",
    "    thirukkural_meaning_train=pd.read_csv(r'../datasets/tamil_thirukkural_train.csv')\n",
    "    thirukkural_meaning_test=pd.read_csv(r'../datasets/tamil_thirukkural_test.csv')\n",
    "    data=pd.concat([thirukkural_meaning_test,thirukkural_meaning_train])\n",
    "    data=data.sort_values(by='Number')\n",
    "    kural_with_meaning=[]\n",
    "    mk_tokens=[]\n",
    "    mv_tokens=[]\n",
    "    sp_tokens=[]\n",
    "    kural_tokens=[]\n",
    "    for index, row in data.iterrows():\n",
    "        mk=row['mk']\n",
    "        mv=row['mv']\n",
    "        sp=row['sp']\n",
    "        kural=row['kural']\n",
    "        tokens=tokenize([kural])[0]\n",
    "        mk= tokenize([mk])[0]\n",
    "        mv= tokenize([mv])[0]\n",
    "        sp= tokenize([sp])[0]\n",
    "        kural_tokens.append(tokens)\n",
    "        mk_tokens.append(mk)\n",
    "        mv_tokens.append(mv)\n",
    "        sp_tokens.append(sp)\n",
    "    kural_mk_mv_sp = []\n",
    "    for author in [mk_tokens,mv_tokens,sp_tokens]:\n",
    "        for i in range(1330):\n",
    "            mk_tokens_0 = author[i]\n",
    "            kural_tokens_0 = kural_tokens[i]\n",
    "            for _ in range(50):\n",
    "                merged = []\n",
    "                i, j = 0, 0\n",
    "                while i < len(mk_tokens_0) and j < len(kural_tokens_0):\n",
    "                    if random.choice([True, False]):\n",
    "                        merged.append(mk_tokens_0[i])\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        merged.append(kural_tokens_0[j])\n",
    "                        j += 1\n",
    "                merged.extend(mk_tokens_0[i:])\n",
    "                merged.extend(kural_tokens_0[j:])\n",
    "                kural_mk_mv_sp.append(merged)\n",
    "    return kural_mk_mv_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens=tokenize(valid_data)\n",
    "train_tokens=tokenize(train_data)\n",
    "parimelazhagar_merged_tokens=get_parimelazhagar_merged_tokens(parimelazhagar_vurai)\n",
    "kural_mk_mv_sp=get_kural_mk_mv_sp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
